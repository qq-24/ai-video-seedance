Now I want to improve this tool by adding new features. Future new video models will be able to simultaneously incorporate audio, video, images, and text for reference and generation, invoked through natural language during generation. Among these, images and text should both be generatable on-the-fly within the tool, and video as well. Audio only needs to be imported. But it should be convenient. Also, the video needs a head-to-tail frame continuation feature, meaning the last frame of the previously generated video becomes the first frame of the next video. Because many times I want to produce long videos but each generation is limited to 15 seconds max, so this kind of continuation is needed.